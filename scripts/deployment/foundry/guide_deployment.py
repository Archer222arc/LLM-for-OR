#!/usr/bin/env python3
"""
Azure AI Foundry æ¨¡å‹éƒ¨ç½²äº¤äº’å¼æŒ‡å¯¼è„šæœ¬

åŠŸèƒ½:
    - é€ä¸ªæŒ‡å¯¼ç”¨æˆ·é€šè¿‡Portaléƒ¨ç½²Foundryæ¨¡å‹
    - è‡ªåŠ¨æ‰“å¼€Portalé“¾æ¥
    - éªŒè¯æ¯ä¸ªæ¨¡å‹éƒ¨ç½²æˆåŠŸ
    - è‡ªåŠ¨æ›´æ–°é…ç½®æ–‡ä»¶å¯ç”¨å·²éƒ¨ç½²æ¨¡å‹
    - ç”Ÿæˆéƒ¨ç½²è¿›åº¦æŠ¥å‘Š

Usage:
    python scripts/guide_foundry_model_deployment.py

Prerequisites:
    - Azure AI Foundry Hubså·²åˆ›å»º
    - ç¯å¢ƒå˜é‡å·²è®¾ç½®ï¼ˆsource ~/.azure_foundry_credentialsï¼‰
    - é…ç½®æ–‡ä»¶å·²åˆ›å»ºï¼ˆconfigs/models/azure_deployments.yamlï¼‰

Created: 2026-01-11
"""

import sys
import json
import webbrowser
from pathlib import Path
from typing import Dict, List
import time

# Add project root to path
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))


# ============================================================================
# æ¨¡å‹é…ç½®
# ============================================================================

MODELS_CONFIG = [
    # Claudeç³»åˆ— (East US 2)
    {
        "key": "claude-opus-4.5",
        "name": "Claude Opus 4.5",
        "hub": "foundry-eastus2",
        "region": "East US 2",
        "model_id": "Anthropic.Claude-Opus-4-5",
        "deployment_type": "Serverless API",
        "portal_url": "https://ai.azure.com/explore/models?selectedCollection=anthropic",
        "pricing": {"input": "$15/1M", "output": "$75/1M"},
        "quota": {"tpm": "80K", "rpm": "600"},
    },
    {
        "key": "claude-sonnet-4.5",
        "name": "Claude Sonnet 4.5",
        "hub": "foundry-eastus2",
        "region": "East US 2",
        "model_id": "Anthropic.Claude-Sonnet-4-5",
        "deployment_type": "Serverless API",
        "portal_url": "https://ai.azure.com/explore/models?selectedCollection=anthropic",
        "pricing": {"input": "$3/1M", "output": "$15/1M"},
        "quota": {"tpm": "160K", "rpm": "1200"},
    },
    {
        "key": "claude-haiku-4.5",
        "name": "Claude Haiku 4.5",
        "hub": "foundry-eastus2",
        "region": "East US 2",
        "model_id": "Anthropic.Claude-Haiku-4-5",
        "deployment_type": "Serverless API",
        "portal_url": "https://ai.azure.com/explore/models?selectedCollection=anthropic",
        "pricing": {"input": "$0.25/1M", "output": "$1.25/1M"},
        "quota": {"tpm": "æ ‡å‡†", "rpm": "æ ‡å‡†"},
    },
    # DeepSeekç³»åˆ— (East US)
    {
        "key": "deepseek-r1",
        "name": "DeepSeek-R1",
        "hub": "foundry-eastus",
        "region": "East US",
        "model_id": "DeepSeek.DeepSeek-R1",
        "deployment_type": "Global Standard",
        "portal_url": "https://ai.azure.com/explore/models?selectedCollection=deepseek",
        "pricing": {"input": "$0.55/1M", "output": "$2.19/1M"},
        "quota": {"tpm": "150K", "rpm": "1000"},
    },
    {
        "key": "deepseek-v3.2",
        "name": "DeepSeek-V3.2",
        "hub": "foundry-eastus",
        "region": "East US",
        "model_id": "DeepSeek.DeepSeek-V3-2",
        "deployment_type": "Global Standard",
        "portal_url": "https://ai.azure.com/explore/models?selectedCollection=deepseek",
        "pricing": {"input": "$0.27/1M", "output": "$1.10/1M"},
        "quota": {"tpm": "æ ‡å‡†", "rpm": "æ ‡å‡†"},
    },
    # Qwenç³»åˆ— (Sweden Central)
    {
        "key": "qwen3-72b",
        "name": "Qwen3-72B-Instruct",
        "hub": "foundry-sweden",
        "region": "Sweden Central",
        "model_id": "Qwen.Qwen3-72B-Instruct",
        "deployment_type": "Serverless API",
        "portal_url": "https://ai.azure.com/explore/models?selectedCollection=qwen",
        "pricing": {"input": "~$0.60/1M", "output": "~$1.80/1M"},
        "quota": {"tpm": "æ ‡å‡†", "rpm": "æ ‡å‡†"},
    },
]

# è¿›åº¦æ–‡ä»¶
PROGRESS_FILE = project_root / ".foundry_deployment_progress.json"


# ============================================================================
# è¿›åº¦ç®¡ç†
# ============================================================================

def load_progress() -> Dict:
    """åŠ è½½éƒ¨ç½²è¿›åº¦"""
    if PROGRESS_FILE.exists():
        with open(PROGRESS_FILE, 'r') as f:
            return json.load(f)
    return {"deployed": [], "failed": []}


def save_progress(progress: Dict):
    """ä¿å­˜éƒ¨ç½²è¿›åº¦"""
    with open(PROGRESS_FILE, 'w') as f:
        json.dump(progress, f, indent=2)


def clear_progress():
    """æ¸…é™¤è¿›åº¦æ–‡ä»¶"""
    if PROGRESS_FILE.exists():
        PROGRESS_FILE.unlink()


# ============================================================================
# éƒ¨ç½²æŒ‡å¯¼
# ============================================================================

def print_header(text: str):
    """æ‰“å°æ ‡é¢˜"""
    print("\n" + "=" * 70)
    print(f"{text:^70}")
    print("=" * 70 + "\n")


def print_model_info(model_config: Dict):
    """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
    print(f"æ¨¡å‹åç§°: {model_config['name']}")
    print(f"Model ID: {model_config['model_id']}")
    print(f"éƒ¨ç½²åç§°: {model_config['key']}")
    print(f"Hub/Project: {model_config['hub']} ({model_config['region']})")
    print(f"éƒ¨ç½²ç±»å‹: {model_config['deployment_type']}")
    print(f"å®šä»·: è¾“å…¥ {model_config['pricing']['input']}, è¾“å‡º {model_config['pricing']['output']}")
    print(f"é…é¢: TPM {model_config['quota']['tpm']}, RPM {model_config['quota']['rpm']}")


def print_deployment_steps(model_config: Dict):
    """æ‰“å°éƒ¨ç½²æ­¥éª¤"""
    print("\néƒ¨ç½²æ­¥éª¤:")
    print("  1. åœ¨æ‰“å¼€çš„Portalé¡µé¢ä¸­æœç´¢å¹¶é€‰æ‹©æ¨¡å‹")
    print("  2. ç‚¹å‡» 'Deploy' æŒ‰é’®")
    print(f"  3. é€‰æ‹©éƒ¨ç½²ç±»å‹: {model_config['deployment_type']}")
    print(f"  4. é€‰æ‹©Hub/Project: {model_config['hub']}")
    print(f"  5. è®¾ç½®éƒ¨ç½²åç§°: {model_config['key']} (å¿…é¡»å®Œå…¨ä¸€è‡´)")
    print("  6. æ¥å—ä½¿ç”¨æ¡æ¬¾å’ŒEULA")
    print("  7. ç¡®è®¤å®šä»·å’Œé…é¢")
    print("  8. ç‚¹å‡» 'Deploy' å¼€å§‹éƒ¨ç½²")
    print("  9. ç­‰å¾…éƒ¨ç½²å®Œæˆï¼ˆé€šå¸¸2-5åˆ†é’Ÿï¼‰")


def deploy_model(model_config: Dict, progress: Dict) -> bool:
    """å¼•å¯¼éƒ¨ç½²å•ä¸ªæ¨¡å‹"""
    print_header(f"éƒ¨ç½² {model_config['name']}")

    # æ£€æŸ¥æ˜¯å¦å·²éƒ¨ç½²
    if model_config['key'] in progress['deployed']:
        print(f"âœ“ æ¨¡å‹ '{model_config['key']}' å·²éƒ¨ç½²ï¼Œè·³è¿‡")
        return True

    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print_model_info(model_config)

    # æ˜¾ç¤ºéƒ¨ç½²æ­¥éª¤
    print_deployment_steps(model_config)

    # è¯¢é—®æ˜¯å¦æ‰“å¼€Portal
    print(f"\nPortalé“¾æ¥: {model_config['portal_url']}")
    response = input("\næ˜¯å¦è‡ªåŠ¨æ‰“å¼€Portalé“¾æ¥? (y/n): ").strip().lower()

    if response == 'y':
        print("æ­£åœ¨æ‰“å¼€Portal...")
        webbrowser.open(model_config['portal_url'])
        time.sleep(2)

    # ç­‰å¾…ç”¨æˆ·å®Œæˆéƒ¨ç½²
    print("\nè¯·åœ¨Portalä¸­å®Œæˆéƒ¨ç½²ï¼Œç„¶åè¿”å›æ­¤å¤„...")
    while True:
        response = input("\néƒ¨ç½²æ˜¯å¦å®Œæˆ? (y/n/skip): ").strip().lower()

        if response == 'y':
            # éªŒè¯éƒ¨ç½²
            print("\næ­£åœ¨éªŒè¯éƒ¨ç½²...")
            if verify_model_deployment(model_config):
                progress['deployed'].append(model_config['key'])
                save_progress(progress)
                return True
            else:
                print("âŒ éƒ¨ç½²éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥Portalä¸­çš„éƒ¨ç½²çŠ¶æ€")
                retry = input("æ˜¯å¦é‡è¯•éªŒè¯? (y/n): ").strip().lower()
                if retry != 'y':
                    progress['failed'].append(model_config['key'])
                    save_progress(progress)
                    return False

        elif response == 'skip':
            print(f"è·³è¿‡æ¨¡å‹ '{model_config['key']}'")
            return False

        elif response == 'n':
            print("è¯·ç»§ç»­åœ¨Portalä¸­å®Œæˆéƒ¨ç½²...")
            time.sleep(1)


def verify_model_deployment(model_config: Dict) -> bool:
    """éªŒè¯æ¨¡å‹éƒ¨ç½²ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    try:
        from src.utils.config_loader import AzureConfigLoader

        # æ£€æŸ¥é…ç½®åŠ è½½
        loader = AzureConfigLoader()
        config = loader.get_foundry_deployment(model_config['key'])

        if config is None:
            print(f"âš  é…ç½®æ–‡ä»¶ä¸­æ¨¡å‹ '{model_config['key']}' æœªå¯ç”¨")
            print("æç¤º: éƒ¨ç½²å®Œæˆåéœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® enabled: true")
            return True  # å‡è®¾Portaléƒ¨ç½²æˆåŠŸï¼Œé…ç½®æ–‡ä»¶ç¨åæ›´æ–°

        # å°è¯•è·å–tokenï¼ˆéªŒè¯è®¤è¯ï¼‰
        try:
            token = loader.get_foundry_auth_token()
            print("âœ“ è®¤è¯éªŒè¯æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âš  è®¤è¯éªŒè¯å¤±è´¥: {e}")
            print("æç¤º: è¯·ç¡®ä¿ç¯å¢ƒå˜é‡å·²æ­£ç¡®è®¾ç½®")
            return True  # å‡è®¾Portaléƒ¨ç½²æˆåŠŸï¼Œè®¤è¯é—®é¢˜å¯èƒ½æ˜¯ç¯å¢ƒå˜é‡æœªåŠ è½½

    except Exception as e:
        print(f"âš  éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
        # è¯¢é—®ç”¨æˆ·
        response = input("Portaléƒ¨ç½²æ˜¯å¦ç¡®å®æˆåŠŸ? (y/n): ").strip().lower()
        return response == 'y'


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    print_header("Azure AI Foundry æ¨¡å‹éƒ¨ç½²æŒ‡å¯¼")

    print("æ­¤è„šæœ¬å°†å¼•å¯¼æ‚¨éƒ¨ç½²ä»¥ä¸‹6ä¸ªæ¨¡å‹:")
    for i, model in enumerate(MODELS_CONFIG, 1):
        print(f"  {i}. {model['name']} ({model['hub']})")

    print("\né‡è¦æç¤º:")
    print("  - ç¡®ä¿å·²åˆ›å»ºAzure AI Foundry Hubs")
    print("  - ç¡®ä¿å·²åŠ è½½ç¯å¢ƒå˜é‡ (source ~/.azure_foundry_credentials)")
    print("  - å‡†å¤‡å¥½æ¥å—ä½¿ç”¨æ¡æ¬¾å’Œå®šä»·")
    print()

    # åŠ è½½è¿›åº¦
    progress = load_progress()

    if progress['deployed']:
        print(f"\nå·²éƒ¨ç½²æ¨¡å‹: {', '.join(progress['deployed'])}")

    if progress['failed']:
        print(f"å¤±è´¥æ¨¡å‹: {', '.join(progress['failed'])}")

    response = input("\næ˜¯å¦ç»§ç»­? (y/n): ").strip().lower()
    if response != 'y':
        print("éƒ¨ç½²å·²å–æ¶ˆ")
        return

    # é€ä¸ªéƒ¨ç½²æ¨¡å‹
    for model_config in MODELS_CONFIG:
        success = deploy_model(model_config, progress)

        if not success:
            print(f"\næ¨¡å‹ '{model_config['key']}' æœªæˆåŠŸéƒ¨ç½²")

        # è¯¢é—®æ˜¯å¦ç»§ç»­
        if model_config != MODELS_CONFIG[-1]:  # ä¸æ˜¯æœ€åä¸€ä¸ªæ¨¡å‹
            response = input("\næ˜¯å¦ç»§ç»­ä¸‹ä¸€ä¸ªæ¨¡å‹? (y/n/quit): ").strip().lower()
            if response == 'quit':
                print("éƒ¨ç½²è¿‡ç¨‹ä¸­æ–­")
                break
            elif response != 'y':
                print("æš‚åœéƒ¨ç½²ï¼Œç¨åå¯é‡æ–°è¿è¡Œæ­¤è„šæœ¬ç»§ç»­")
                break

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print_header("éƒ¨ç½²æ±‡æ€»")

    total = len(MODELS_CONFIG)
    deployed = len(progress['deployed'])
    failed = len(progress['failed'])
    pending = total - deployed - failed

    print(f"æ€»è®¡: {total} ä¸ªæ¨¡å‹")
    print(f"âœ“ å·²éƒ¨ç½²: {deployed}")
    print(f"âœ— å¤±è´¥: {failed}")
    print(f"â³ å¾…éƒ¨ç½²: {pending}")

    if progress['deployed']:
        print(f"\nå·²éƒ¨ç½²æ¨¡å‹:")
        for key in progress['deployed']:
            print(f"  - {key}")

    if deployed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹éƒ¨ç½²å®Œæˆ!")
        print("\nä¸‹ä¸€æ­¥æ“ä½œ:")
        print("  1. æ›´æ–°é…ç½®æ–‡ä»¶å¯ç”¨æ¨¡å‹:")
        print("     python scripts/update_foundry_config.py --enable-deployed")
        print("\n  2. éªŒè¯éƒ¨ç½²:")
        print("     python scripts/verify_foundry_deployment.py")

        # è¯¢é—®æ˜¯å¦æ¸…é™¤è¿›åº¦
        response = input("\næ˜¯å¦æ¸…é™¤éƒ¨ç½²è¿›åº¦è®°å½•? (y/n): ").strip().lower()
        if response == 'y':
            clear_progress()
            print("è¿›åº¦è®°å½•å·²æ¸…é™¤")
    else:
        print(f"\nè¿˜æœ‰ {pending} ä¸ªæ¨¡å‹å¾…éƒ¨ç½²")
        print("é‡æ–°è¿è¡Œæ­¤è„šæœ¬å¯ç»§ç»­éƒ¨ç½²")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\néƒ¨ç½²å·²ä¸­æ–­")
        print("é‡æ–°è¿è¡Œæ­¤è„šæœ¬å¯ç»§ç»­éƒ¨ç½²")
        sys.exit(0)
