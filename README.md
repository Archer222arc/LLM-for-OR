# LLM-for-OR: Agentic Operations Research with Large Language Models

**NeurIPS 2026 Research Project**

> From Static Translation to Dynamic Self-Correction in Operations Research

## Overview

This project develops evaluation benchmarks for LLM agents in Operations Research (OR) and Operations Management (OM). The core contribution is **OR-Debug-Bench**, a Gym-like MDP environment for solver infeasibility diagnosis and recovery.

### Research Directions

| Tier | Direction | Benchmark | Status |
|------|-----------|-----------|--------|
| 1 | A | OR-Debug-Bench | ðŸš§ In Development |
| 1 | B | OR-Bias-Bench | ðŸ“‹ Planned |
| 1 | C | OR-Compliance-Bench | ðŸ“‹ Planned |
| 2 | D-F | Formulation/Transfer/Disruption | ðŸ“‹ Future |
| 3 | G-H | Safety-RL/Multi-Agent | ðŸ“‹ Future |

## Key Features

- **MDP-based Evaluation**: Evaluate LLM agents as policies navigating solver states
- **Verifiable Rewards**: Solver status provides deterministic, noise-free feedback
- **Process Metrics**: Beyond outcome accuracyâ€”measure diagnostic reasoning quality
- **Saboteur Agent**: Systematic error injection for benchmark data generation

## Installation

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/LLM-for-OR.git
cd LLM-for-OR

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .
```

### Prerequisites

- Python 3.9+
- Gurobi Optimizer (academic license: free)
- CUDA (optional, for GRPO training)

## Project Structure

```
LLM-for-OR/
â”œâ”€â”€ docs/                    # Research documentation
â”‚   â”œâ”€â”€ 00_PROJECT_OVERVIEW.md
â”‚   â”œâ”€â”€ directions/          # Research direction details
â”‚   â””â”€â”€ archive/             # Original reports
â”œâ”€â”€ src/                     # Core code
â”‚   â”œâ”€â”€ environments/        # MDP environments
â”‚   â”œâ”€â”€ agents/              # LLM/RL agents
â”‚   â”œâ”€â”€ solvers/             # Gurobi/Pyomo interfaces
â”‚   â”œâ”€â”€ data_generation/     # Saboteur agent
â”‚   â””â”€â”€ evaluation/          # Metrics computation
â”œâ”€â”€ configs/                 # Configuration files
â”œâ”€â”€ data/                    # Datasets
â”œâ”€â”€ experiments/             # Experiment configs
â””â”€â”€ notebooks/               # Analysis notebooks
```

## Quick Start

```python
from src.environments import SolverGym
from src.agents import LLMAgent

# Create environment
env = SolverGym(solver="gurobi")

# Load agent
agent = LLMAgent(model="gpt-4o")

# Run episode
state = env.reset(problem="infeasible_tsp.mps")
done = False
while not done:
    action = agent.act(state)
    state, reward, done, info = env.step(action)

print(f"Recovery: {info['recovered']}, Steps: {info['steps']}")
```

## Documentation

- [Project Overview](docs/00_PROJECT_OVERVIEW.md)
- [Research Context](docs/01_RESEARCH_CONTEXT.md)
- [OR-Debug-Bench Details](docs/directions/A_OR_Debug_Bench/)
- [Literature Review](docs/03_LITERATURE_REVIEW.md)

## Citation

```bibtex
@article{llm-for-or-2026,
  title={OR-Debug-Bench: A Gym Environment for Solver Infeasibility Diagnosis and Recovery},
  author={Ao, Ruicheng},
  journal={NeurIPS},
  year={2026}
}
```

## License

MIT License - see [LICENSE](LICENSE) for details.

## Contact

- **Author**: Ruicheng Ao
- **Institution**: MIT IDSS
- **Email**: [your-email]

---

*Last updated: January 2026*
